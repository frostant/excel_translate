# trans_excel.py
# ä¾èµ–ï¼špip install openpyxl tiktoken tqdm openai
import os
import re
from openpyxl import load_workbook
from tqdm import tqdm
import tiktoken
from openai import OpenAI
import io
import sys
import tempfile

try:
    import streamlit as st
except Exception:
    st = None  # å…è®¸æ—  streamlit ç¯å¢ƒä¸‹ä»¥ CLI è¿è¡Œ

# ========== åŸºæœ¬é…ç½® ==========
INPUT_XLSX  = "table.xlsx"              # è¾“å…¥æ–‡ä»¶
OUTPUT_XLSX = "output_translated.xlsx"  # è¾“å‡ºæ–‡ä»¶ï¼ˆä¸è¦†ç›–åŸæ–‡ä»¶ï¼‰
MODEL = "gpt-4o"
MAX_TOKENS = 200000  # ä¸€æ¬¡è¿è¡Œå†…çš„æ€»tokenä¸Šé™

# ä»ç¯å¢ƒå˜é‡è¯»å– API Keyï¼Œæ›´å®‰å…¨ï¼šexport OPENAI_API_KEY="xxx"
api_key = os.getenv("OPENAI_API_KEY")
if not api_key:
    raise RuntimeError("è¯·å…ˆè®¾ç½®ç¯å¢ƒå˜é‡ OPENAI_API_KEY å†è¿è¡Œç¨‹åº")
client = OpenAI(api_key=api_key)


# ========== è®¡æ•°/ç¼“å­˜ ==========
used_tokens = 0
encoding = tiktoken.encoding_for_model(MODEL)
translation_cache = {}  # key = (text, task_context) -> str

def count_tokens(text: str) -> int:
    return len(encoding.encode(text))

# ========== é¢„è¯†åˆ«ï¼šè¡¨æ ¼ç±»å‹/ç”¨é€” ==========
def detect_sheet_context(ws) -> str:
    """æŠ½æ ·åˆ—åä¸å†…å®¹ï¼Œè°ƒç”¨ä¸€æ¬¡æ¨¡å‹ï¼Œè·å–æ–‡æ¡£ç±»å‹/ç”¨é€”ä¸€å¥è¯æ¦‚è¿°"""
    def _truncate_list_str(lst, max_items=5, max_len=40):
        out = []
        for s in lst[:max_items]:
            if isinstance(s, str):
                s = s.strip()
                if len(s) > max_len:
                    s = s[:max_len] + 'â€¦'
                out.append(s)
            else:
                out.append(str(s))
        return out

    headers, samples = [], []

    # æŠ½å‰ 5 ä¸ªéç©ºåˆ—åï¼ˆå‡å®šç¬¬ä¸€è¡Œä¸ºè¡¨å¤´ï¼‰
    for col in ws.iter_cols(min_row=1, max_row=1):
        header = col[0].value
        if header and isinstance(header, str):
            headers.append(header)
    headers = headers[:5]

    # æŠ½æ · 5 æ¡éç©ºæ–‡æœ¬ï¼ˆç¬¬2~4è¡Œï¼‰
    for col in ws.iter_cols(min_row=2, max_row=4):
        for cell in col:
            if cell.value and isinstance(cell.value, str):
                samples.append(cell.value)
            if len(samples) >= 5:
                break
        if len(samples) >= 5:
            break

    headers_compact = ','.join(_truncate_list_str(headers, 5, 20))
    samples_compact = '|'.join(_truncate_list_str(samples, 5, 30))

    detect_prompt = (
        f"åˆ—:{headers_compact}\næ ·æœ¬:{samples_compact}\n"
        f"è¯·ç”¨8~16å­—åˆ¤æ–­è¡¨æ ¼ç±»å‹ä¸ç”¨é€”ã€‚åªè¾“å‡ºä¸€å¥è¯ã€‚"
    )

    resp = client.chat.completions.create(
        model=MODEL,
        messages=[
            {"role": "system", "content": "ä½ æ˜¯åˆ†ç±»å™¨ã€‚ä»…è¾“å‡ºä¸€å¥è¯ã€‚"},
            {"role": "user", "content": detect_prompt}
        ]
    )
    result = resp.choices[0].message.content.strip()
    return result if result else "é€šç”¨è¡¨æ ¼ç¿»è¯‘"

# ========== ç¿»è¯‘ä¸»å‡½æ•° ==========
def translate_text(text: str, task_context: str = "", model: str = MODEL) -> str:
    """ç¿»è¯‘å•å…ƒæ ¼æ–‡æœ¬ï¼šè·³ç©º/æ— è‹±æ–‡ã€ç¼“å­˜ã€token é™åˆ¶ã€ç³»ç»Ÿä¸Šä¸‹æ–‡æç¤º"""
    global used_tokens

    # è·³è¿‡ç©ºå€¼
    if text is None or str(text).strip() == "":
        return "" if text is None else str(text)

    text = str(text)

    # è‹¥æ— è‹±æ–‡å­—ç¬¦ï¼ŒæŒ‰ä½ çš„éœ€æ±‚è·³è¿‡ç¿»è¯‘ä»¥çœæˆæœ¬ï¼ˆå¦‚éœ€å…¨é‡ç¿»è¯‘å¯æ”¹ä¸ºç›´æ¥èµ°æ¨¡å‹ï¼‰
    if not re.search(r'[a-zA-Z]', text):
        return text

    # ç¼“å­˜ï¼ˆè€ƒè™‘ä¸Šä¸‹æ–‡ï¼‰
    cache_key = (text, task_context)
    if cache_key in translation_cache:
        return translation_cache[cache_key]

    # æç®€ã€å¼ºçº¦æŸçš„ user æç¤ºï¼Œç³»ç»Ÿæç¤ºé‡Œæ³¨å…¥åœºæ™¯
    prompt = f"{text}\nâ€”â€”ä»…è¯‘ä¸ºä¸­æ–‡ï¼š"
    input_tokens = count_tokens(prompt) + count_tokens(task_context)

    # token ä¸Šé™æ£€æŸ¥ï¼ˆç²—ç•¥æŒ‰è¾“å…¥ä¼°ï¼›æ›´ä¸¥è°¨å¯åŠ æ¨¡å‹è¿”å› usageï¼‰
    # global MAX_TOKENS
    if used_tokens + input_tokens > MAX_TOKENS:
        return "[å·²è¾¾åˆ°ç¿»è¯‘ä¸Šé™]"

    try:
        resp = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": f"ä½ æ˜¯{task_context}ç¿»è¯‘å™¨ã€‚ä»…ç»™ä¸­æ–‡è¯‘æ–‡ï¼Œä¸å¾—è§£é‡Šã€‚æ­§ä¹‰æŒ‰è¯¥åœºæ™¯å¸¸ç”¨å«ä¹‰ã€‚"},
                {"role": "user", "content": prompt}
            ]
        )
        result = resp.choices[0].message.content
        # è®¡å…¥ç²—ç•¥ tokenï¼ˆå¦‚éœ€ç²¾ç¡®ï¼Œè¯·åœ¨ resp ä¸­è¯»å– usage.total_tokens å†ç´¯åŠ ï¼‰
        output_tokens = count_tokens(result)
        used_tokens += input_tokens + output_tokens

        translation_cache[cache_key] = result
        return result
    except Exception as e:
        return f"[é”™è¯¯]: {e}"


# ========== ä¸»æµç¨‹ ==========
def process_workbook(input_path: str, output_path: str = None, model: str = MODEL,
                     progress_cb=None, use_tqdm: bool = True):
    """å¤„ç†å¹¶ç¿»è¯‘æ•´ä¸ªå·¥ä½œç°¿ï¼›
    - input_path: è¾“å…¥ xlsx è·¯å¾„
    - output_path: è¾“å‡º xlsx è·¯å¾„ï¼›è‹¥ä¸º None åˆ™ä¸è½ç›˜ï¼ˆå¯é…åˆè¿”å›å†…å­˜ï¼‰
    - model: ä½¿ç”¨æ¨¡å‹
    - progress_cb: å½¢å¦‚ progress_cb(done, total) çš„å›è°ƒï¼ˆä¾› Streamlit ä½¿ç”¨ï¼‰
    - use_tqdm: æ˜¯å¦ä½¿ç”¨ tqdm è¿›åº¦æ¡ï¼ˆCLI ä¸‹ Trueï¼ŒStreamlit ä¸‹ Falseï¼‰
    è¿”å›ï¼šå¦‚æœ output_path ä¸º Noneï¼Œåˆ™è¿”å› BytesIOï¼›å¦åˆ™è¿”å› output_pathã€‚
    """
    global used_tokens
    used_tokens = 0  # æ¯æ¬¡å¤„ç†é‡ç½®è®¡æ•°

    wb = load_workbook(input_path)
    ws = wb.active

    # é¢„è¯†åˆ«åœºæ™¯
    task_context = detect_sheet_context(ws)
    print("è¯†åˆ«åˆ°çš„æ–‡æ¡£ç±»å‹/ç”¨é€”ï¼š", task_context)

    all_cells = [cell for row in ws.iter_rows() for cell in row]
    total = len(all_cells)

    iterator = all_cells
    if use_tqdm:
        iterator = tqdm(all_cells, desc="Translating")

    done = 0
    for cell in iterator:
        if isinstance(cell.value, str):
            translated = translate_text(cell.value, task_context=task_context, model=model)
            cell.value = translated
        done += 1
        if progress_cb is not None:
            progress_cb(done, total)
        if used_tokens >= MAX_TOKENS:
            break

    # è¾“å‡º
    if output_path:
        wb.save(output_path)
        return output_path
    else:
        bio = io.BytesIO()
        wb.save(bio)
        bio.seek(0)
        return bio


def main():
    # CLIï¼šè¯»å– INPUT_XLSX å¹¶å†™å…¥ OUTPUT_XLSX
    # out = process_workbook(INPUT_XLSX, OUTPUT_XLSX, model=MODEL, progress_cb=None, use_tqdm=True)
    # print(f"å®Œæˆï¼šè¾“å‡ºæ–‡ä»¶ -> {OUTPUT_XLSX}ï¼Œç´¯è®¡ä¼°ç®— tokens = {used_tokens}")
    pass 


# ========== Streamlit ç½‘é¡µ MVP ==========


def run_streamlit_app():
    if st is None:
        raise RuntimeError("æœªå®‰è£… streamlitï¼Œè¯·å…ˆ `pip install streamlit` å†è¿è¡Œï¼šstreamlit run trans_excel.py")
    global MAX_TOKENS  # ä¿è¯ä¸‹æ–¹è¯»å–/èµ‹å€¼ä¸è§¦å‘ SyntaxError
    st.set_page_config(page_title="Excel ç¿»è¯‘åŠ©æ‰‹ MVP", page_icon="ğŸ“„", layout="centered")
    st.title("ğŸ“„ Excel ç¿»è¯‘åŠ©æ‰‹ MVP")

    with st.expander("è¿è¡Œå‚æ•°", expanded=False):
        # global MAX_TOKENS
        model = st.selectbox("æ¨¡å‹", [MODEL, "gpt-4o-mini"], index=0)
        max_tokens = st.number_input("æœ¬æ¬¡è¿è¡Œçš„æœ€å¤§ token ä¸Šé™", min_value=10_000, max_value=1_000_000, value=MAX_TOKENS, step=10_000)
        st.caption("ä¸ºé¿å…æˆæœ¬å¤±æ§ï¼Œå¯é€‚å½“é™ä½æœ¬æ¬¡ä¸Šé™ã€‚")

    uploaded = st.file_uploader("ä¸Šä¼  Excel æ–‡ä»¶ (.xlsx)", type=["xlsx"]) 

    # åˆå§‹åŒ–ä¼šè¯æ€ï¼šä¸ä½œä¸ºç¼“å­˜å¤ç”¨é€»è¾‘ï¼Œè€Œæ˜¯ä»…æ ‡è®°ä¸€æ¬¡ä»»åŠ¡å®ŒæˆçŠ¶æ€
    if "translated_file" not in st.session_state:
        st.session_state["translated_file"] = None
    if "processed" not in st.session_state:
        st.session_state["processed"] = False

    if uploaded is not None and not st.session_state["processed"]:
        # æ˜¾ç¤ºâ€œå¼€å§‹ç¿»è¯‘â€æŒ‰é’®ï¼Œé¿å…ä¸Šä¼ å³è‡ªåŠ¨è§¦å‘
        if st.button("å¼€å§‹ç¿»è¯‘"):
            # å°†ä¸Šä¼ å†…å®¹è½åˆ°ä¸´æ—¶æ–‡ä»¶
            with tempfile.NamedTemporaryFile(delete=False, suffix=".xlsx") as tmp_in:
                tmp_in.write(uploaded.read())
                in_path = tmp_in.name

            # è¿›åº¦æ¡
            prog = st.progress(0)
            def progress_cb(done, total):
                if total:
                    prog.progress(min(100, int(done * 100 / total)))

            # åŠ¨æ€è°ƒæ•´å…¨å±€ä¸Šé™ä¸æ¨¡å‹
            MAX_TOKENS = int(max_tokens)

            try:
                st.write("å¼€å§‹å¤„ç†â€¦â€¦")
                bio = process_workbook(in_path, output_path=None, model=model, progress_cb=progress_cb, use_tqdm=False)
                st.session_state["translated_file"] = bio.getvalue()
                st.session_state["processed"] = True
                st.success("å¤„ç†å®Œæˆï¼")
            finally:
                # åˆ é™¤åŸå§‹ä¸´æ—¶æ–‡ä»¶ï¼Œé¿å…ä¸‹æ¬¡ rerun ç»§ç»­å¤„ç†
                try:
                    os.remove(in_path)
                except Exception:
                    pass

    # è‹¥å·²å®Œæˆï¼Œåˆ™ä»…å±•ç¤ºä¸‹è½½æŒ‰é’®ï¼Œä¸å†è§¦å‘å¤„ç†
    if st.session_state["processed"] and st.session_state["translated_file"] is not None:
        st.download_button(
            "â¬‡ï¸ ä¸‹è½½ç¿»è¯‘åçš„æ–‡ä»¶",
            data=st.session_state["translated_file"],
            file_name="translated.xlsx",
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
        )
        st.info("å¦‚éœ€é‡æ–°ç¿»è¯‘æ–°æ–‡ä»¶ï¼Œè¯·åˆ·æ–°é¡µé¢æˆ–æ¸…ç©ºä¼šè¯ï¼ˆRerunï¼‰åå†æ¬¡ä¸Šä¼ .")


if __name__ == "__main__":
    # å¦‚æœé€šè¿‡ streamlit å¯åŠ¨ï¼ˆ`streamlit run trans_excel.py`ï¼‰ï¼Œä¸‹è¡Œä¸ä¼šæ‰§è¡Œ
    # æ™®é€š CLI å¯åŠ¨ï¼špython trans_excel.py
    # if "streamlit.web.bootstrap" in sys.modules:
    #     pass
    # else:
    #     main()
    # main()
        # ç”¨ streamlit å¯åŠ¨ï¼šè¿›å…¥ç½‘é¡µï¼›å‘½ä»¤è¡Œå¯åŠ¨ï¼šèµ° CLI
    if st is not None and any(m.startswith("streamlit") for m in sys.modules.keys()):
        run_streamlit_app()
    else:
        main()